{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "acc=[]\n",
    "pathw2v='C:\\\\a\\\\glove.6B.50d.txt'\n",
    "w2vp = open(pathw2v, 'r',encoding='utf-8')\n",
    "b=[]\n",
    "for line in w2vp:\n",
    "    b.append(line[:-1])\n",
    "words = [str(i.split(' ')[0]) for i in b]\n",
    "word2vector0= [i.split(' ')[1:51] for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vector=[[float(i) for i in j] for j in word2vector0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "worddic={}\n",
    "for i in range(len(words)):\n",
    "    worddic[words[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pandas.core.frame import DataFrame\n",
    "path = 'C:\\\\a\\\\opinions.tsv'\n",
    "data = pd.read_table(path,header=None,skiprows=1,names=['Sentiment','Review'])\n",
    "X=data.Review\n",
    "y = data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3458\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size= 0.5)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vector=[]\n",
    "X_test_vector=[]\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3458\n"
     ]
    }
   ],
   "source": [
    "for i in X_train:\n",
    "    t1=TextBlob(str(i)).words\n",
    "    t2=np.zeros(50)\n",
    "    sum=0\n",
    "    for j in t1:\n",
    "        if j not in worddic:\n",
    "            continue\n",
    "        t3=np.array(word2vector[worddic[j.lower()]])\n",
    "        t2=t2+t3\n",
    "        sum+=1\n",
    "    X_train_vector.append(t2/sum)\n",
    "print(len(X_train_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3459\n"
     ]
    }
   ],
   "source": [
    "for i in X_test:\n",
    "    t1=TextBlob(i).words\n",
    "    t2=np.zeros(50)\n",
    "    sum=0\n",
    "    for j in t1:\n",
    "        if j not in worddic:\n",
    "            continue\n",
    "        t3=np.array(word2vector[worddic[j.lower()]])\n",
    "        t2=t2+t3\n",
    "        sum+=1\n",
    "    X_test_vector.append(t2/sum)\n",
    "\n",
    "print(len(X_test_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=[]\n",
    "Y_test=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3458\n"
     ]
    }
   ],
   "source": [
    "for i in y_train:\n",
    "    Y_train.append(i)\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3459\n"
     ]
    }
   ],
   "source": [
    "for i in y_test:\n",
    "    Y_test.append(i)\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3458\n",
      "3458\n"
     ]
    }
   ],
   "source": [
    "X_train_Vector=np.array(X_train_vector)\n",
    "\n",
    "Y_Train=np.array(Y_train)\n",
    "X_test_Vector=np.array(X_test_vector)\n",
    "Y_Test=np.array(Y_test)\n",
    "\n",
    "X_train_Vector=np.nan_to_num(X_train_Vector)\n",
    "Y_Train=np.nan_to_num(Y_Train)\n",
    "X_test_Vector=np.nan_to_num(X_test_Vector)\n",
    "Y_Test=np.nan_to_num(Y_Test)\n",
    "print(len(X_train_Vector))\n",
    "print(len(Y_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes\n",
      "Accuracy Score: 80.8326105810928%\n",
      "Confusion Matrix: \n",
      "[[1077  409]\n",
      " [ 254 1719]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB(priors=None)\n",
    "clf.fit(X_train_Vector,Y_Train)\n",
    "y_pred = clf.predict(X_test_Vector)\n",
    "print('\\nNaive Bayes')\n",
    "acc.append(metrics.accuracy_score(Y_Test,y_pred)*100)\n",
    "print('Accuracy Score: ',metrics.accuracy_score(Y_Test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(Y_Test,y_pred), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "Accuracy Score: 95.46111592945938%\n",
      "Confusion Matrix: \n",
      "[[1413   73]\n",
      " [  84 1889]]\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train_Vector,Y_Train)\n",
    "y_pred = LR.predict(X_test_Vector)\n",
    "print('\\nLogistic Regression')\n",
    "acc.append(metrics.accuracy_score(Y_Test,y_pred)*100)\n",
    "print('Accuracy Score: ',metrics.accuracy_score(Y_Test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(Y_Test,y_pred), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine\n",
      "Accuracy Score: 95.63457646718705%\n",
      "Confusion Matrix: \n",
      "[[1425   61]\n",
      " [  90 1883]]\n"
     ]
    }
   ],
   "source": [
    "SVM = LinearSVC()\n",
    "SVM.fit(X_train_Vector,Y_Train)\n",
    "y_pred = SVM.predict(X_test_Vector)\n",
    "print('\\nSupport Vector Machine')\n",
    "acc.append(metrics.accuracy_score(Y_Test,y_pred)*100)\n",
    "print('Accuracy Score: ',metrics.accuracy_score(Y_Test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(Y_Test,y_pred), sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K Nearest Neighbors (NN = 3)\n",
      "Accuracy Score: 94.6516334200636%\n",
      "Confusion Matrix: \n",
      "[[1349  137]\n",
      " [  48 1925]]\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 3)\n",
    "KNN.fit(X_train_Vector,Y_Train)\n",
    "y_pred = KNN.predict(X_test_Vector)\n",
    "print('\\nK Nearest Neighbors (NN = 3)')\n",
    "acc.append(metrics.accuracy_score(Y_Test,y_pred)*100)\n",
    "print('Accuracy Score: ',metrics.accuracy_score(Y_Test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(Y_Test,y_pred), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6917\n",
      "6917\n"
     ]
    }
   ],
   "source": [
    "X_all=[]\n",
    "for i in X:\n",
    "    t1=TextBlob(str(i)).words\n",
    "    t2=np.zeros(50)\n",
    "    sum=0\n",
    "    for j in t1:\n",
    "        if j not in worddic:\n",
    "            continue\n",
    "        t3=np.array(word2vector[worddic[j.lower()]])\n",
    "        t2=t2+t3\n",
    "        sum+=1\n",
    "    X_all.append(t2/sum)\n",
    "print(len(X_all))\n",
    "Y_all=[]\n",
    "for i in y:\n",
    "    Y_all.append(i)\n",
    "print(len(Y_all))\n",
    "X_All=np.array(X_all)\n",
    "Y_All=np.array(Y_all)\n",
    "\n",
    "\n",
    "X_All=np.nan_to_num(X_All)\n",
    "Y_All=np.nan_to_num(Y_All)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qiuyuqi is shanbaodi's son\n",
      "qiuyuqi is shanbaodi's son\n",
      "qiuyuqi\n",
      "is\n",
      "shanbaodi\n",
      "'s\n",
      "son\n",
      "[[ 0.14160875  0.253145   -0.10196125  0.0596025   0.32188875  0.19217375\n",
      "  -0.20987326 -0.0258375  -0.05630625  0.0307625   0.0896015   0.20101\n",
      "  -0.23909363 -0.18444087  0.16757875  0.07221888 -0.03155125  0.115986\n",
      "  -0.08897     0.13703087 -0.13388539  0.144575   -0.1388605   0.00471375\n",
      "   0.143606   -0.870675   -0.20841625 -0.05751625 -0.038473    0.04285387\n",
      "   1.0901     -0.1559805  -0.11549     0.01289325  0.10638187 -0.07561825\n",
      "   0.00496125  0.08302625  0.1009225  -0.08242875 -0.02156675  0.2152675\n",
      "  -0.1958025  -0.17057263  0.00787263 -0.00456125 -0.15909    -0.29911875\n",
      "   0.08520113  0.10268363]]\n",
      "['1']\n",
      "The review is predicted Positive\n",
      "sbd is qyq's son\n",
      "sbd is qyq's son\n",
      "sbd\n",
      "is\n",
      "qyq\n",
      "'s\n",
      "son\n",
      "[[ 0.02036167  0.176927   -0.0432725   0.04878667  0.15172583  0.14886333\n",
      "  -0.13735609 -0.14864167  0.0050625   0.00059583  0.07605517  0.22559\n",
      "  -0.23045992  0.02528108 -0.0074725   0.14930425  0.04736083  0.06918558\n",
      "  -0.24058     0.14615142 -0.08447434  0.22976667 -0.01743783 -0.0417275\n",
      "   0.12071733 -0.59325083 -0.22868583 -0.14151083 -0.0429695   0.14391092\n",
      "   0.584375   -0.068412   -0.14969917  0.1387205   0.19342125 -0.11061967\n",
      "  -0.03725083  0.02615333 -0.03292667 -0.00441583 -0.00917367  0.18483667\n",
      "  -0.09546583  0.01652658  0.03082508 -0.0702975  -0.05015417 -0.22665\n",
      "   0.11524825  0.06274817]]\n",
      "['1']\n",
      "The review is predicted Positive\n",
      "I am very happy\n",
      "I am very happy\n",
      "I\n",
      "am\n",
      "very\n",
      "happy\n",
      "[[ 6.72810667e-02  4.31576400e-02 -5.36593333e-02 -8.01566667e-02\n",
      "   1.68231333e-01 -1.18085867e-01 -3.51666000e-02  9.89766667e-02\n",
      "  -1.72224000e-01  3.50080000e-02 -8.63666667e-03  1.67233333e-02\n",
      "  -6.95600000e-02  1.97413333e-03  1.67548000e-01  1.02460000e-01\n",
      "   7.32820000e-02  1.22400667e-01 -5.15417933e-02 -7.82033333e-02\n",
      "  -8.52778667e-02  1.70862000e-01  1.04294000e-01  1.41957333e-01\n",
      "   2.49586667e-01 -2.75746667e-01 -1.22696667e-01  9.66600000e-02\n",
      "   1.53588000e-01  1.49666667e-03  5.97366667e-01  7.17066667e-02\n",
      "  -2.30353333e-02  4.03333333e-04 -5.34513333e-02 -1.21230667e-01\n",
      "   8.11364667e-02  6.35006667e-02 -4.06880000e-02 -9.26560000e-02\n",
      "  -4.84800000e-03 -7.48780000e-02 -1.27720000e-02  7.40526000e-02\n",
      "   3.60553333e-02  4.17728667e-02 -8.00413333e-02 -1.52479333e-02\n",
      "   3.80806667e-02  2.04736667e-01]]\n",
      "['1']\n",
      "The review is predicted Positive\n",
      "sounds not well\n",
      "sounds not well\n",
      "sounds\n",
      "not\n",
      "well\n",
      "[[ 5.19266667e-02 -2.13450000e-02 -4.79527000e-02 -3.58805556e-02\n",
      "   3.14111111e-02  3.05205556e-02 -5.69455556e-02 -1.60997222e-02\n",
      "  -6.97344444e-02  9.43364444e-02  1.64972222e-02  6.22922222e-02\n",
      "   1.08888889e-03  2.62367222e-02  4.33600000e-02  5.61412222e-02\n",
      "   4.25800000e-02  1.68622222e-02 -2.65866667e-02 -1.42385000e-01\n",
      "  -4.93363333e-02  6.49544444e-02  8.02083333e-02  3.34433333e-02\n",
      "   1.06696889e-01 -2.47227778e-01 -1.37302778e-01  5.56410556e-02\n",
      "   8.29157778e-02 -1.03684444e-01  5.86283333e-01 -1.88005556e-02\n",
      "   1.98611111e-03 -9.17072222e-02  3.57100000e-02 -1.96800000e-02\n",
      "   5.30188889e-02  3.07722222e-03 -3.11794444e-02 -1.21181111e-02\n",
      "  -1.53428333e-02  3.36194444e-02 -9.50000000e-05  5.26754056e-02\n",
      "   2.77393889e-02  5.94007778e-02 -1.34822222e-02  1.63785556e-02\n",
      "  -3.11639444e-02  5.85968889e-02]]\n",
      "['1']\n",
      "The review is predicted Positive\n"
     ]
    }
   ],
   "source": [
    "LR_complete=LinearSVC()\n",
    "LR_complete.fit(X_All,Y_All)\n",
    "while True:\n",
    "    test=input()\n",
    "    print(test)\n",
    "    test1=TextBlob(test).words\n",
    "    t2=np.zeros(50)\n",
    "    for j in test1:\n",
    "            print(j)\n",
    "            if j not in worddic:\n",
    "                continue\n",
    "            t3=np.array(word2vector[worddic[j.lower()]])\n",
    "            t2=t2+t3\n",
    "            sum+=1\n",
    "\n",
    "    test_dtm=t2/sum\n",
    "    test_dtm=np.nan_to_num([test_dtm])\n",
    "    print(test_dtm)\n",
    "    predLabel = LR_complete.predict(test_dtm)\n",
    "    print(predLabel)\n",
    "    tags = ['Negative','Positive']\n",
    "    #Display Output\n",
    "    print('The review is predicted',tags[int(predLabel[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "x=['NB','LR','SVM','KNN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
